# System
TIMEZONE=America/Santiago

# Ollama
OLLAMA_ENDPOINT="http://localhost:11434"
OLLAMA_MODEL="hf.co/unsloth/Qwen3-4B-Instruct-2507-GGUF:Q4_K_XL"
OLLAMA_CONTEXT_WINDOW=81920
OLLAMA_MEMORY_LIMIT=5
OLLAMA_ENABLE=0
OLLAMA_DEFAULT_MODEL=0

# OpenAI
OPENAI_API_KEY=
OPENAI_MODEL="gpt-5-nano"
OPENAI_MEMORY_LIMIT=10
OPENAI_ENABLE=0
OPENAI_DEFAULT_MODEL=1

# xAI
XAI_MODEL="grok-4-fast-reasoning"
XAI_API_KEY=
XAI_MEMORY_LIMIT=10
XAI_ENABLE=0
XAI_DEFAULT_MODEL=0

# NextJS Public Envs
NEXT_PUBLIC_OLLAMA_ENDPOINT=$OLLAMA_ENDPOINT
NEXT_PUBLIC_OLLAMA_MODEL=$OLLAMA_MODEL
NEXT_PUBLIC_OLLAMA_CONTEXT_WINDOW=$OLLAMA_CONTEXT_WINDOW
NEXT_PUBLIC_OLLAMA_MEMORY_LIMIT=$OLLAMA_MEMORY_LIMIT
NEXT_PUBLIC_OLLAMA_ENABLE=$OLLAMA_ENABLE
NEXT_PUBLIC_OLLAMA_DEFAULT_MODEL=$OLLAMA_DEFAULT_MODEL

NEXT_PUBLIC_OPENAI_MODEL=$OPENAI_MODEL
NEXT_PUBLIC_OPENAI_MEMORY_LIMIT=$OPENAI_MEMORY_LIMIT
NEXT_PUBLIC_OPENAI_ENABLE=$OPENAI_ENABLE
NEXT_PUBLIC_OPENAI_DEFAULT_MODEL=$OPENAI_DEFAULT_MODEL

NEXT_PUBLIC_XAI_MODEL=$XAI_MODEL
NEXT_PUBLIC_XAI_MEMORY_LIMIT=$XAI_MEMORY_LIMIT
NEXT_PUBLIC_XAI_ENABLE=$XAI_ENABLE
NEXT_PUBLIC_XAI_DEFAULT_MODEL=$XAI_DEFAULT_MODEL
